{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in\n",
      "Changing to /DATASETS/NOAA/G02135/north/daily/data\n",
      "['N_seaice_extent_climatology_1981-2010_v3.0.csv', 'N_seaice_extent_daily_v3.0.csv', 'N_seaice_extent_daily_v3.0.csv.bak']\n",
      "Downloading...N_seaice_extent_climatology_1981-2010_v3.0.csv\n",
      "Downloading...N_seaice_extent_daily_v3.0.csv\n",
      "Downloading...N_seaice_extent_daily_v3.0.csv.bak\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'221-Goodbye. You uploaded 0 and downloaded 3814 kbytes.\\n221 Logout.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ftplib import FTP\n",
    "import os\n",
    "\n",
    "### The following 3 variables can be changed ###\n",
    "# 1. Set the directory you would like to download the files to\n",
    "destdir='//home///shreyansh//python programs//sea and ice project'\n",
    "\n",
    "# 2. Set the path to the FTP directory that contains the data you wish to download.\n",
    "# This example is for the daily northern hemisphere data from the Sea Ice Index\n",
    "# https://nsidc.org/data/g02135\n",
    "directory = '/DATASETS/NOAA/G02135/north/daily/data'\n",
    "\n",
    "# 3. Set the password which will be your email address\n",
    "password = 'sunnytyagi886@gmail.com'\n",
    "\n",
    "############################################\n",
    "### Don't need to change this code below ###\n",
    "############################################\n",
    "# FTP server\n",
    "ftpdir = 'sidads.colorado.edu'\n",
    "\n",
    "#Connect and log in to the FTP\n",
    "print('Logging in')\n",
    "ftp = FTP(ftpdir)\n",
    "ftp.login('anonymous',password)\n",
    "\n",
    "# Change to the directory where the files are on the FTP\n",
    "print('Changing to '+ directory)\n",
    "ftp.cwd(directory)\n",
    "\n",
    "# Get a list of the files in the FTP directory\n",
    "files = ftp.nlst()\n",
    "files = files[2:]\n",
    "print(files)\n",
    "\n",
    "#Change to the destination directory on own computer where you want to save the files\n",
    "os.chdir(destdir)\n",
    "\n",
    "#Download all the files within the FTP directory\n",
    "for file in files:\n",
    "    print('Downloading...' + file)\n",
    "    ftp.retrbinary('RETR ' + file, open(file, 'wb').write)\n",
    "\n",
    "#Close the FTP connection\n",
    "ftp.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package pandas:\n",
      "\n",
      "NAME\n",
      "    pandas\n",
      "\n",
      "DESCRIPTION\n",
      "    pandas - a powerful data analysis and manipulation library for Python\n",
      "    =====================================================================\n",
      "    \n",
      "    **pandas** is a Python package providing fast, flexible, and expressive data\n",
      "    structures designed to make working with \"relational\" or \"labeled\" data both\n",
      "    easy and intuitive. It aims to be the fundamental high-level building block for\n",
      "    doing practical, **real world** data analysis in Python. Additionally, it has\n",
      "    the broader goal of becoming **the most powerful and flexible open source data\n",
      "    analysis / manipulation tool available in any language**. It is already well on\n",
      "    its way toward this goal.\n",
      "    \n",
      "    Main Features\n",
      "    -------------\n",
      "    Here are just a few of the things that pandas does well:\n",
      "    \n",
      "      - Easy handling of missing data in floating point as well as non-floating\n",
      "        point data.\n",
      "      - Size mutability: columns can be inserted and deleted from DataFrame and\n",
      "        higher dimensional objects\n",
      "      - Automatic and explicit data alignment: objects can be explicitly aligned\n",
      "        to a set of labels, or the user can simply ignore the labels and let\n",
      "        `Series`, `DataFrame`, etc. automatically align the data for you in\n",
      "        computations.\n",
      "      - Powerful, flexible group by functionality to perform split-apply-combine\n",
      "        operations on data sets, for both aggregating and transforming data.\n",
      "      - Make it easy to convert ragged, differently-indexed data in other Python\n",
      "        and NumPy data structures into DataFrame objects.\n",
      "      - Intelligent label-based slicing, fancy indexing, and subsetting of large\n",
      "        data sets.\n",
      "      - Intuitive merging and joining data sets.\n",
      "      - Flexible reshaping and pivoting of data sets.\n",
      "      - Hierarchical labeling of axes (possible to have multiple labels per tick).\n",
      "      - Robust IO tools for loading data from flat files (CSV and delimited),\n",
      "        Excel files, databases, and saving/loading data from the ultrafast HDF5\n",
      "        format.\n",
      "      - Time series-specific functionality: date range generation and frequency\n",
      "        conversion, moving window statistics, date shifting and lagging.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _config (package)\n",
      "    _libs (package)\n",
      "    _testing (package)\n",
      "    _typing\n",
      "    _version\n",
      "    api (package)\n",
      "    arrays (package)\n",
      "    compat (package)\n",
      "    conftest\n",
      "    core (package)\n",
      "    errors (package)\n",
      "    io (package)\n",
      "    plotting (package)\n",
      "    testing\n",
      "    tests (package)\n",
      "    tseries (package)\n",
      "    util (package)\n",
      "\n",
      "SUBMODULES\n",
      "    _hashtable\n",
      "    _lib\n",
      "    _tslib\n",
      "    offsets\n",
      "\n",
      "FUNCTIONS\n",
      "    __getattr__(name)\n",
      "        # GH 27101\n",
      "\n",
      "DATA\n",
      "    IndexSlice = <pandas.core.indexing._IndexSlice object>\n",
      "    NA = <NA>\n",
      "    NaT = NaT\n",
      "    __docformat__ = 'restructuredtext'\n",
      "    __git_version__ = '945c9ed766a61c7d2c0a7cbb251b6edebf9cb7d5'\n",
      "    describe_option = <pandas._config.config.CallableDynamicDoc object>\n",
      "    get_option = <pandas._config.config.CallableDynamicDoc object>\n",
      "    options = <pandas._config.config.DictWrapper object>\n",
      "    reset_option = <pandas._config.config.CallableDynamicDoc object>\n",
      "    set_option = <pandas._config.config.CallableDynamicDoc object>\n",
      "\n",
      "VERSION\n",
      "    1.3.4\n",
      "\n",
      "FILE\n",
      "    /usr/local/lib/python3.8/dist-packages/pandas/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "help(pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Extent\n",
      "0      10.231\n",
      "1      10.420\n",
      "2      10.557\n",
      "3      10.670\n",
      "4      10.777\n",
      "...       ...\n",
      "14051   7.791\n",
      "14052   7.903\n",
      "14053   8.005\n",
      "14054   8.077\n",
      "14055   8.132\n",
      "\n",
      "[14056 rows x 1 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"//home//shreyansh/python programs//sea and ice project//sea and ice.csv\", usecols = ['Extent'])\n",
    "print(df)\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "import csv as csv\n",
    "path_to_import ='//home//shreyansh/python programs//sea and ice project//sea and ice.csv'\n",
    "import_file = pd.read_csv(path_to_import,engine='python',encoding='utf-8-sig')\n",
    "\n",
    "headers = pd.read_csv(path_to_import,nrows=0).columns.tolist()\n",
    "\n",
    "columns = ['Extent']\n",
    "\n",
    "path_to_selected = '//home//shreyansh/python programs//sea and ice project//extent_fetched.csv'\n",
    "pd.read_csv(path_to_import,usecols=columns, sep=',').to_csv('extent_fetched.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
